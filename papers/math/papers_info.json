{
  "2302.01910v1": {
    "title": "Low progress math in a high performing system",
    "authors": [
      "A. Jamaludin",
      "A. I. Jabir",
      "F. J. Wang",
      "A. L. Tan"
    ],
    "summary": "Math anxiety negatively relates to math performance. This negative\nrelationship may be exacerbated in low-progress math learners. However, there\nare limited studies on math anxiety among low progress learners in a\nparadoxically high performing education system like Singapore. To fill this\nresearch gap, this research analysed the anxiety profiles of 151 students who\nwere in the math learning support intervention program administered by the\nMinistry of Education, Singapore (MOE). We examined the complex relationship\ncentred in math anxiety with relevant variables such as demographic\ncharacteristics, working memory and math performance. Limitations and future\ndirections are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2302.01910v1",
    "published": "2023-01-26"
  },
  "2501.05096v1": {
    "title": "Solutions to Problems in Amer. Math. Monthly, Math. Magazine, College Math. J., Elemente der Math.,Crux Math., EMS Newsletter Math. Gazette",
    "authors": [
      "Raymond Mortini"
    ],
    "summary": "In this arxiv-post I present my solutions (published or not) to Problems that\nappeared in Amer. Math. Monthly, Math. Magazine, Elemente der Mathematik and\nCRUX, that were mostly done in collaboration with Rudolf Rupp. Some of them\n(including a few own proposals which were published) were also done in\ncooperation with Rainer Br\\\"uck, Bikash Chakraborty, Pamela Gorkin, Gerd\nHerzog, J\\'er\\^ome No\\\"el, Peter Pflug and Amol Sasane.",
    "pdf_url": "http://arxiv.org/pdf/2501.05096v1",
    "published": "2025-01-09"
  },
  "2410.16930v4": {
    "title": "Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes",
    "authors": [
      "Bryan R. Christ",
      "Zack Gottesman",
      "Jonathan Kropko",
      "Thomas Hartvigsen"
    ],
    "summary": "Math reasoning is an active area of Large Language Model (LLM) research\nbecause it is a hallmark of artificial intelligence and has implications in\nseveral domains, including math education. However, few works have explored how\nmath reasoning is encoded within LLM parameters and if it is a skill that can\nbe isolated within models. Doing so could allow targeted intervention to\nimprove math performance without altering non-math behavior and foster\nunderstanding of how models encode math reasoning. We introduce Math\nNeurosurgery (MathNeuro), a computationally efficient method we use to isolate\nmath-specific parameters in LLMs using only forward passes. MathNeuro builds on\nexisting work by using weights and activations to calculate parameter\nimportance, but isolates math-specific parameters by filtering out those\nimportant for general language tasks. Through pruning parameters MathNeuro\nidentifies, we delete a LLM's math reasoning ability without significantly\nimpacting its general language ability. Scaling the identified parameters by a\nsmall constant improves a pretrained or instruction-tuned LLM's performance by\n4-17% on GSM8K and 5-35% on MATH while leaving non-math behavior unaltered.\nMathNeuro is also data efficient: most of its effectiveness holds when\nidentifying math-specific parameters using a single sample. MathNeuro\nhighlights the potential for future work to intervene on math-specific\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2410.16930v4",
    "published": "2024-10-22"
  }
}